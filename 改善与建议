import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter
import jieba

# 设置中文显示
plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签
plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号

# 读取数据
df = pd.read_csv('睡眠质量数据集.csv')

# 1. 数据概览
print("数据前5行：")
print(df.head())
print("\n数据基本信息：")
print(df.info())
print("\n描述性统计：")
print(df.describe())



# 改善建议的词频分析
# 提取所有改善建议并分词
all_suggestions = ' '.join(df['改善建议'].dropna().astype(str))
words = jieba.lcut(all_suggestions)
word_counts = Counter(words)

# 过滤掉单个字的词和无意义的词
filtered_words = {word: count for word, count in word_counts.items() 
                 if len(word) > 1 and word not in ['建议', '专业', '咨询', '考虑']}

# 生成词云
wordcloud = WordCloud(width=800, height=400, background_color='white', font_path='simhei.ttf').generate_from_frequencies(filtered_words)

plt.figure(figsize=(12, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('改善建议词云')
plt.show()
